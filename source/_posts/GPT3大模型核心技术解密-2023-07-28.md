---
title: GPT3大模型核心技术解密
date: 2023-07-28 9:30:00
categories:
  - 大模型
tags:
  - GPT1
  - GPT2
  - GPT3
  - 生成式预训练
description: gpt3重磅发布，在九大nlp领域取得成功显著。更少的领域数据、且不经过fine-tuning
cover: https://cdn.jsdelivr.net/gh/1oscar/image_house@main/10022.jpg
---


## 背景

### 当前模型缺陷

对领域内有标签数据的过分依赖：
预训练+精调的两段式框架，需要领域标注数据，否则很难取得不错的效果
标注数据的成本高

领域数据分布的过拟合
在精调阶段，拟合训练数据分布，数据较少->过拟合->泛化能力下降
其他领域使用受限

### Fine-tuning移除必要性：

新任务需要大量的标记数据->不利于语言模型应用

微调效果好不能说明预训练模型泛化性好
比如，可能是过拟合预训练的训练数据。

人类接触下游语言任务不需要大量样本，只需要一句对新任务的描述或者几个案例。

当前nlp技术所欠缺的：无缝融合+切换多个任务的能力

### 移除fine-tuning方案

meta-learning元学习
比微调的结果差很多。 

Large scale transformer 
transformer模型参数不断膨胀，参数的增加给模型带来显著的性能提升
有paper提出模型增大，loss在变小。

作者猜想一个更大的transformer模型应该会有更好的学习能力，所以训练一个1750亿参数的自回归语言模型-gpt3，测试这一架设
（同gpt2同原理同架构，参数更大，移除fine-tuning尝试） 



## 方案

### 模型架构 

与GPT-2相同点：
 模型和架构，包括模型初始化、归一化和输入编码

与GPT-2不同点:
交替的密集和局部稀疏注意力模式，类似于 Sparse Transformer

**模型参数:**
共训练8组不同大小模型
研究尺度对模型影响
可用来作为模型越大,性能越好证明

N_parameters: 参数个数
n-layers: 总的层数
d-model: 隐藏层维度
N-heads: attention head的数量
D-head:  attention head的维度

`参数规模从1250w一直到1750亿`

![参数对比](https://cdn.jsdelivr.net/gh/1oscar/image_house@main/20230728222841.png)

---
### 训练数据

![训练数据](https://cdn.jsdelivr.net/gh/1oscar/image_house@main/20230728222921.png)

```
大小为45TB，过滤后为570GB
1个epoch:CommonCrawl 和 Books2
其他：2-3epoch

```

**训练数据筛选 步骤**

过滤common crawl: 使用高质量参考语料库

模糊去重:文档粒度，包括数据集内部和跨数据集

添加已知高质量语料库进入训练集中


**过滤common crawl：**

分类器：Spark 分词使用HashingTF特征

模型：LR

正例:WebText  负例: 未经过滤的Common crawl 

设置阈值，过滤	


**已知问题：**
删除训练集和测试集重叠部分。做不到100%删除，存在部分重叠。

训练成本高昂，无法重新训练。

### 训练过程


**超参：**

```
优化器： adam
batch-size: 3.2M
Learn-rate:0.6*10^-4
无重复采样
正则0.1
参数：1750e
神经元个数：12288
head的数量：96
层个数：96
```

![参数](https://cdn.jsdelivr.net/gh/1oscar/image_house@main/20230728222841.png)


### 模型评估

**评估指标**

不同的任务，评估采用的标准和数据集是不同

LAMBADA 和 Storycloze：没有可用的监督训练集，因此从训练集中抽取条件示例并在测试集上进行评估

多项选择题，提供K个上下文加正确完成的示例，然后提供一个仅包含上下文的示例，并比较每个完成的LM似然

**评估分类设置**

设置one-shot,zero-shot,few-shot三种方式。


## GPT1 VS GPT2 VS GPT3模型对比

![模型对比](https://cdn.jsdelivr.net/gh/1oscar/image_house@main/20230728223349.png)


## 实验结果

### 在3种条件下评估GPT-3的性能


**Few-shot（FS)**
小样本; 给模型10-100个样本; 不能更新权重

**定义**：允许输入数条范例和一则任务说明
    示例：向模型输入 “这个任务要求将中文翻译为英文。你好 ->hello，再见 ->goodbye，购买 ->purchase，销售 ->”，然后要求模型预测下一个输出应该是什么，正确答案应为 “sell”。


**One-shot(1S)**
1个样本;不会更新权重;

**定义**：只允许输入一条范例和一则任务说明
示例：向模型输入 “这个任务要求将中文翻译为英文。你好 ->hello，销售 ->”，然后要求模型预测下一个输出应该是什么，正确答案应为 “sell”。


**Zero-shot(0S)**
最接近人类，只有自然语言描述的问题，没有样例 ; 不会权重更新。

**定义**：不允许输入任何范例，只允许输入一则任务说明
示例：向模型输入 “这个任务要求将中文翻译为英文。销售 ->”，然后要求模型预测下一个输出应该是什么，正确答案应为 “sell”。


### 结论

参数越大，few-shot表现越好。

1750参数曲线表现最好。

![结论](https://cdn.jsdelivr.net/gh/1oscar/image_house@main/20230728223639.png)


### 传统语言建模

单词预测，句子和段落补全,完形填空等 

![传统语言建模1](https://cdn.jsdelivr.net/gh/1oscar/image_house@main/20230728223727.png)

![传统语言建模2](https://cdn.jsdelivr.net/gh/1oscar/image_house@main/20230728223744.png)

PTB数据集：GPT3 zero shot 性能比state of the art提高整整15分

Lambada数据集：阅读一个段落，预测最后一个单词。Few-shot acc效果没有超过sota，但是也超过zero-shot，one-shot。


不同参数下gpt-3 zero-shot, one-shot,few-shot的在lambda数据集性能比较

![传统语言建模3](https://cdn.jsdelivr.net/gh/1oscar/image_house@main/20230728223832.png)

### 问答QA任务

用来测试事实性的知识,即你问我答。

在triviaQA任务: 
one-shot,few-shot都超过了fine tuned state of the art。 

![问答QA任务](https://cdn.jsdelivr.net/gh/1oscar/image_house@main/20230728223925.png)


### 翻译任务


```
  表现好：
  法语  ->  英语
  德语  -> 英语
  罗马尼亚语  ->  英语

  表现差：
  英语 ->其他语言
```

![](https://cdn.jsdelivr.net/gh/1oscar/image_house@main/20230728224106.png)


**翻译能力和模型参数** 

参数指数增->性能线性增

注:BLEU 是用来评估机器翻译的指标

![翻译](https://cdn.jsdelivr.net/gh/1oscar/image_house@main/20230728224151.png)


## 数据污染预防与评估

### 预防：

训练数据来自于互联网，训练可能包含一些测试集

准确检测互联网数据集中的测试污染是一个新的研究领域，目前尚未建立最佳实践

OpenAI 最初尝试解决污染：删除训练数据与基准测试集的任何重叠。不幸的是，由于一个漏洞，只能部分删除所有检测到的重叠部分。  由于训练成本的原因，重新训练模型是不可行的。

### 评估

GPT-2 重叠分析：训练和测试数据集有一定的重叠，但受到污染的数据仅有几个百分点，对结果没有产生显著影响。

GPT-3 数据量巨大，训练集过度拟合程度并不显著。预计污染可能会经常发生，但其影响可能不会像人们担心的那样大

![数据污染评估](https://cdn.jsdelivr.net/gh/1oscar/image_house@main/20230728224308.png)

Gpt3-训练曲线:对比训练loss和验证集loss，虽然存在一定的gap，但随着模型大小和训练时间的增加gap变化幅度很小，这表明过拟合基本没有，即数据污染影响小。

## 局限性

**一：文本合成**

虽然总体质量很高，但 GPT-3 有时仍会在语义上重复自己，在足够长的段落中开始失去连贯性，自相矛盾

**二：离散语言任务**

在“物理常识”方面有特殊的困难.举例： 具体来说，GPT-3 在“If I put cheese into the fridge, will it melt?”这类问题上有困难 。

**三：结构和算法上的局限性**

专注于自回归语言模型中的上下文学习行为, 采样和计算似然函数都很简单, 在包括填空任务，涉及查看并比较两个内容的任务，或需要重新阅读或仔细考虑长篇文章然后生成非常简短答案的任务表现差。

**四：few-shot 学习一个局限**

不确定 few-shot 学习是否实际上会在推理时“从零开始”学习新任务

**五：成本**

昂贵且难以进行推理-（1500w美金）。
解决这个问题的一个可能的未来方向是将大型模型蒸馏为特定任务的小模型。

**六：可解释性**

存在一些深度学习系统普遍存在的限制，它的决策不容易解释

## 影响力


**一：语言模型误用**

例如，虚假信息，垃圾邮件，网络钓鱼，滥用法律和政府程序，欺诈学术论文写作, 社交媒体假信息机器人
安全风险：三星芯片涉密信息泄露

**二：公平与偏见**

数据偏差可能导致模型偏见，可能伤害到一些人。

性别：中性变量的职业是被男性概率比女性更高。
       测试的388种职业中，有83%的职业更有可能是男性。可能是女性职业包括助产士、护士、接待员、管家等。

种族：探究种族如何影响情绪，使用Senti WordNet 来测量情绪，以确定在每个种族中出现的不相称的词汇。每个种族中，清晰词的分数不同。亚洲人，积极的词分数较高。

宗教：研究了哪些词与无神论、佛教、基督教、印度教、伊斯兰教和犹太教等宗教术语共出现。以伊斯兰教为例，“暴力”、“恐怖主义” 等词与“伊斯兰”相关的比例要高于与其他宗教相关的比例。

**三：能源**

实际的大规模预训练需要大量的计算，这是能源密集型的。
举例：10块 v100 gpu算力，训练gpt3需要10年。
举例：模型蒸馏降低此类模型的成本。

## 相关工作

**一：** 增加语言模型的参数数量和计算量研究
直接增加 Transformer 模型的大小，等比例扩展参数和计算算力
侧重于增加参数数量而没有增加计算量
增加计算量而不增加参数

**二：** 规模对语言模型性能的影响研究
随着自回归语言模型的扩大，损失呈现出平滑的幂律趋势

三：减少模型内存研究
模型蒸馏方法

四：新的few-shot 学习的方式
探索将预训练语言模型与梯度下降相结合进行 随着自回归语言模型的扩大，损失呈现出平滑的幂律趋势研究

五：OpenAI 继续专注于纯自回归语言模型
既为了专注于上下文学习性能，也为了减少大型模型实现的复杂性
……



## 我的点评

这就是最近大火的chatgpt3的算法模型，模型部分目前不开源。


